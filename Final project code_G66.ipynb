{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7960dbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in d:\\anaconda\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in d:\\anaconda\\lib\\site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests>=2.20->openai) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda\\lib\\site-packages (from aiohttp->openai) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\anaconda\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\anaconda\\lib\\site-packages (from aiohttp->openai) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda\\lib\\site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c61d5b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (20221105)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in d:\\anaconda\\lib\\site-packages (from pdfminer.six) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in d:\\anaconda\\lib\\site-packages (from pdfminer.six) (41.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in d:\\anaconda\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e17c282",
   "metadata": {},
   "source": [
    "## To extract content from a PDF and save it as a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c567a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "def extract_text_from_pdf_with_pdfminer(pdf_path):\n",
    "    text = extract_text(pdf_path)\n",
    "    return text\n",
    "\n",
    "def save_text_to_file(text, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "\n",
    "pdf_path = r'D:\\DeepLearningonepage.pdf'\n",
    "text = extract_text_from_pdf_with_pdfminer(pdf_path)\n",
    "\n",
    "output_txt_path = r'D:\\DeepLearningonepage.txt'\n",
    "save_text_to_file(text, output_txt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0b0861",
   "metadata": {},
   "source": [
    "## To read a text file with GPT-4 and identify formulas, presenting them in LaTeX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3afcfc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# set up an OpenAI API key, follow these steps\n",
    "# we use a string of numbers instead of our used key just for safety\n",
    "openai.api_key = \"0123456789\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b297f37d",
   "metadata": {},
   "source": [
    "## Txt Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ee64026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Based on the content of example_text, please identify all the formulas and change them into latex format. Then show me the new content.\n",
      "New_Text: The text with the formulas in latex format is as follows:\n",
      "\n",
      "2.1. Warm up: a fast matrix-based approach to computing the output from a neural network\n",
      "\n",
      "41\n",
      "\n",
      "\\[j = \\sigma \\left(\\sum_{k} w^{l}_{jk} a^{l-1}_{k} + b^{l}_{j}\\right)\\]\n",
      "\n",
      "where the sum is over all neurons k in the (l-1)-th layer. To rewrite this expression in a matrix form we define a weight matrix \\(w^{l}\\) for each layer, l. The entries of the weight matrix \\(w^{l}\\) are just the weights connecting to the l-th layer of neurons, that is, the entry in the j-th row and k-th column is \\(w^{l}_{jk}\\). Similarly, for each layer l we define a bias vector, \\(b^{l}\\). You can probably guess how this works – the components of the bias vector are just the values \\(b^{l}_{j}\\), one component for each neuron in the l-th layer. And finally, we define an activation vector \\(a^{l}\\) whose components are the activations \\(a^{l}_{j}\\). The last ingredient we need to rewrite 2.1 in a matrix form is the idea of vectorizing a function such as \\(\\sigma\\). We met vectorization briefly in the last chapter, but to recap, the idea is that we want to apply a function such as \\(\\sigma\\) to every element in a vector v. We use the obvious notation \\(\\sigma(v)\\) to denote this kind of elementwise application of a function. That is, the components of \\(\\sigma(v)\\) are just \\(\\sigma(v)_{j} = \\sigma(v_{j})\\). As an example, if we have the function \\(f (x) = x^{2}\\) then the vectorized form of f has the effect\n",
      "\n",
      "\\[\\sigma \\left(\\begin{matrix} 2 \\\\ 3 \\end{matrix}\\right) = \\begin{matrix} f (2) \\\\ f (3) \\end{matrix} = \\begin{matrix} 4 \\\\ 9 \\end{matrix}\\]\n",
      "\n",
      "that is, the vectorized f just squares every element of the vector.\n",
      "\n",
      "With these notations in mind, Equation 2.1 can be rewritten in the beautiful and compact vectorized form\n",
      "\n",
      "\\[a^{l} = \\sigma(w^{l} a^{l-1} + b^{l})\\]\n",
      "\n",
      "This expression gives us a much more global way of thinking about how the activations in one layer relate to activations in the previous layer: we just apply the weight matrix to the activations, then add the bias vector, and finally apply the \\(\\sigma\\) function. That global view is often easier and more succinct (and involves fewer indices!) than the neuron-by-neuron view we’ve taken to now. Think of it as a way of escaping index hell, while remaining precise about what’s going on. The expression is also useful in practice, because most matrix libraries provide fast ways of implementing matrix multiplication, vector addition, and vectorization. Indeed, the code (see 1.6) in the last chapter made implicit use of this expression to compute the behavior of the network.\n",
      "\n",
      "When using Equation 2.3 to compute \\(a^{l}\\), we compute the intermediate quantity \\( z^{l-1} \\equiv w^{l} a^{l-1} + b^{l}\\) along the way. This quantity turns out to be useful enough to be worth naming: we call \\(z^{l}\\) the weighted input to the neurons in layer l. We’ll make considerable use of the weighted input \\( z^{l} \\) later in the chapter. Equation 2.3 is sometimes written in terms of the weighted input, as \\(a^{l}_{j} = \\sigma(z^{l}_{j})\\). It’s also worth noting that \\( z^{l} \\) has components \\( z^{l}_{j} \\), that is, \\(z^{l}_{j}\\) is just the weighted input to the activation function for neuron j in layer l.\n",
      "\n",
      "By the way, it’s this expression that motivates the quirk in the \\(w^{l}_{jk}\\) notation mentioned earlier. If we used j to index the input neuron, and k to index the output neuron, then we’d need to replace the weight matrix in Equation 2.3 by the transpose of the weight matrix. That’s a small change, but annoying, and we’d lose the easy simplicity of saying (and thinking) “apply the weight matrix to the activations”.\n"
     ]
    }
   ],
   "source": [
    "class TxtRecognizer:\n",
    "    def __init__(self, model=\"gpt-4-0613\", result_length=2048, with_prices=True):\n",
    "        self.model = model\n",
    "        self.with_prices = with_prices\n",
    "        self.result_length = result_length\n",
    "\n",
    "    def process(self, query: str, example_text: str):\n",
    "        # Construct conversational prompts\n",
    "        prompt = f\"{example_text}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "\n",
    "        # Generate responses using the Chat Completion interface\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=self.result_length,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        # Extract responses\n",
    "        answer = response.choices[0].message['content'] if response.choices else \"No answer available.\"\n",
    "        return answer\n",
    "\n",
    "# read the content of txt file\n",
    "def read_text_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "# the path of txt file\n",
    "txt_file_path = 'D:\\DeepLearningonepage.txt'\n",
    "example_text = read_text_from_file(txt_file_path)\n",
    "\n",
    "# text the query\n",
    "query = \"Based on the content of example_text, please identify all the formulas and change them into latex format. Then show me the new content.\"\n",
    "txt_recognizer = TxtRecognizer()\n",
    "\n",
    "print(f\"\\nQuery: {query}\")\n",
    "new_text = txt_recognizer.process(query, example_text)\n",
    "print(f\"New_Text: {new_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aaee40",
   "metadata": {},
   "source": [
    "## TeacherAssistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e01e74e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Questions:\n",
      "1. What is the function of the weight matrix \\(w^{l}\\) in a neural network?\n",
      "2. How is the bias vector \\(b^{l}\\) defined for each layer in a neural network?\n",
      "3. What is the role of the activation vector \\(a^{l}\\) in a neural network?\n",
      "4. Explain the concept of vectorizing a function such as \\(\\sigma\\) in the context of neural networks.\n",
      "5. How can you apply the function \\(f(x) = x^{2}\\) to a vector in a vectorized form?\n",
      "6. How can Equation 2.1 be rewritten in a vectorized form?\n",
      "7. What is the global way of thinking about how the activations in one layer relate to activations in the previous layer of a neural network?\n",
      "8. How is the \"weighted input\" \\(z^{l}\\) defined in the context of a neural network?\n",
      "9. How is Equation 2.3 sometimes written in terms of the weighted input?\n",
      "10. What is the significance of the notation \\(z^{l}_{j}\\) in the context of a neural network?\n",
      "11. Why is the \\(w^{l}_{jk}\\) notation used instead of using j to index the input neuron and k to index the output neuron?\n",
      "12. Why is it beneficial to use matrix multiplication, vector addition, and vectorization in the context of neural networks?\n",
      "13. How does the expression \\(a^{l} = \\sigma(w^{l} a^{l-1} + b^{l})\\) help in understanding the behavior of a neural network?\n",
      "14. What is the importance of \\( z^{l-1} \\equiv w^{l} a^{l-1} + b^{l}\\) in the computation of \\(a^{l}\\)?\n"
     ]
    }
   ],
   "source": [
    "class TeacherAssistant:\n",
    "    def __init__(self, model=\"gpt-4-0613\", result_length=500):\n",
    "        self.model = model\n",
    "        self.result_length = result_length\n",
    "\n",
    "    def generate_questions(self, text, num_questions=14):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Based on the following text, generate {num_questions} relevant exam questions:\\n\\n{text}\"}\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            max_tokens=self.result_length,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        questions = response.choices[0].message['content'] if response.choices else \"No questions available.\"\n",
    "        return questions\n",
    "\n",
    "# the original text\n",
    "example_text = new_text\n",
    "\n",
    "# test TeacherAssistant class\n",
    "teacher_assistant = TeacherAssistant()\n",
    "\n",
    "# generate the questions\n",
    "generated_questions = teacher_assistant.generate_questions(example_text)\n",
    "print(f\"Generated Questions:\\n{generated_questions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df438a",
   "metadata": {},
   "source": [
    "## similarity of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ab1d5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9436])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Check the relativity between the text generated by GPT-4-0613 and original material content\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# prepare text\n",
    "question_by_GPT4 =generated_questions\n",
    "\n",
    "question_from_text = new_text\n",
    "texts = [question_from_text, question_by_GPT4]\n",
    "\n",
    "# encode text\n",
    "encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Extract features from the embedding layer\n",
    "embeddings = model_output.last_hidden_state.mean(dim=1)\n",
    "\n",
    "# compute the similarity\n",
    "cosine_similarity_ques_GPT4 = torch.nn.functional.cosine_similarity(embeddings[0].unsqueeze(0), embeddings[1].unsqueeze(0))\n",
    "print(cosine_similarity_ques_GPT4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdff993",
   "metadata": {},
   "source": [
    "## Student Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a3bd06a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query[1]: 1. What is the function of the weight matrix \\(w^{l}\\) in a neural network?\n",
      "Answer: The weight matrix \\(w^{l}\\) in a neural network plays a crucial role in determining the output of the network. Each entry in the weight matrix, \\(w^{l}_{jk}\\), represents the weight connecting the k-th neuron in the (l-1)-th layer to the j-th neuron in the l-th layer. The weight matrix is used to apply these weights to the activations from the previous layer. When calculating the activations for the current layer, the weight matrix is multiplied with the activation vector from the previous layer. This operation is part of the process that transforms the input data within the network to produce the final output. In other words, the weight matrix helps to control how much influence each input (from the previous layer's neurons) has on the next layer's neurons. The weight matrices are typically initialized randomly and are adjusted during the learning process to improve the performance of the neural network.\n",
      "\n",
      "Query[2]: 2. How is the bias vector \\(b^{l}\\) defined for each layer in a neural network?\n",
      "Answer: The bias vector \\(b^{l}\\) for each layer in a neural network is defined as a vector whose components are the bias values \\(b^{l}_{j}\\) for each neuron in the l-th layer.\n",
      "\n",
      "Query[3]: 3. What is the role of the activation vector \\(a^{l}\\) in a neural network?\n",
      "Answer: The activation vector \\(a^{l}\\) in a neural network represents the activations of each neuron in a particular layer l. In other words, it contains the output values of all neurons in that layer. The role of the activation vector is crucial as it helps in propagating information from one layer to the next in the neural network. The output from one layer (represented by the activation vector) becomes the input for the next layer. Thus, it is instrumental in the functioning and performance of the neural network. The activation vector allows for the global view of the network's behavior, making the process of understanding and computation easier and more efficient.\n",
      "\n",
      "Query[4]: 4. Explain the concept of vectorizing a function such as \\(\\sigma\\) in the context of neural networks.\n",
      "Answer: Vectorizing a function, such as \\(\\sigma\\), in the context of neural networks refers to the process of applying the function to every element in a vector. This is usually done for efficiency reasons as it allows for parallel computation of the function across the vector's elements. This concept becomes particularly useful when working with high-dimensional data, which is often the case in neural networks.\n",
      "\n",
      "For instance, the function \\(\\sigma\\) might be applied to the vector of weighted inputs to a layer in a neural network. Instead of computing the \\(\\sigma\\) function for each input one at a time, we can vectorize the function and compute it for all inputs simultaneously. \n",
      "\n",
      "In the notation \\(\\sigma(v)\\), this denotes elementwise application of the function, which means the components of \\(\\sigma(v)\\) are just \\(\\sigma(v)_{j} = \\sigma(v_{j})\\). This vectorized approach simplifies the notation, makes the computation more efficient, and provides a more global view of the operations taking place within the neural network.\n",
      "\n",
      "Query[5]: 5. How can you apply the function \\(f(x) = x^{2}\\) to a vector in a vectorized form?\n",
      "Answer: To apply the function \\(f(x) = x^{2}\\) to a vector in a vectorized form, you would apply the function to each component of the vector individually. For example, if you had a vector v = \\(\\begin{matrix} 2 \\\\ 3 \\end{matrix}\\), applying the function \\(f(x) = x^{2}\\) to this vector in a vectorized form would be as follows:\n",
      "\n",
      "\\[f \\left(\\begin{matrix} 2 \\\\ 3 \\end{matrix}\\right) = \\begin{matrix} f(2) \\\\ f(3) \\end{matrix} = \\begin{matrix} 4 \\\\ 9 \\end{matrix}\\]\n",
      "\n",
      "So, the vectorized form of f just squares every element of the vector.\n",
      "\n",
      "Query[6]: 6. How can Equation 2.1 be rewritten in a vectorized form?\n",
      "Answer: Equation 2.1 can be rewritten in a vectorized form as \\(a^{l} = \\sigma(w^{l} a^{l-1} + b^{l})\\). This equation represents how the activations in one layer relate to the activations in the previous layer: the weight matrix is applied to the activations, then the bias vector is added, and finally, the \\(\\sigma\\) function is applied. This approach is more global, succinct, and provides an efficient way of implementing matrix multiplication, vector addition, and vectorization with most matrix libraries.\n",
      "\n",
      "Query[7]: 7. What is the global way of thinking about how the activations in one layer relate to activations in the previous layer of a neural network?\n",
      "Answer: The global way of thinking about how the activations in one layer relate to activations in the previous layer of a neural network involves applying the weight matrix to the activations from the previous layer, adding the bias vector, and then applying the σ function. This approach provides a more succinct and comprehensive view of the process, which is often easier to understand and implement than a neuron-by-neuron perspective. This global view also allows for faster computations thanks to the use of matrix libraries that provide quick ways of implementing matrix multiplication, vector addition, and vectorization.\n",
      "\n",
      "Query[8]: 8. How is the \"weighted input\" \\(z^{l}\\) defined in the context of a neural network?\n",
      "Answer: The \"weighted input\" \\(z^{l}\\) in the context of a neural network is defined as the product of the weight matrix and the activation of the previous layer, plus the bias. This is represented in the equation \\(z^{l} = w^{l} a^{l-1} + b^{l}\\). It is called the \"weighted input\" because it represents the combined effect of the weights and activations from the previous layer, adjusted by the bias, before the activation function is applied. This weighted input \\(z^{l}\\) serves as the input to the activation function for the neurons in layer l.\n",
      "\n",
      "Query[9]: 9. How is Equation 2.3 sometimes written in terms of the weighted input?\n",
      "Answer: Equation 2.3 is sometimes written in terms of the weighted input as \\(a^{l}_{j} = \\sigma(z^{l}_{j})\\). Here, \\(z^{l}_{j}\\) is the weighted input to the activation function for neuron j in layer l.\n",
      "\n",
      "Query[10]: 10. What is the significance of the notation \\(z^{l}_{j}\\) in the context of a neural network?\n",
      "Answer: The notation \\(z^{l}_{j}\\) in the context of a neural network refers to the weighted input to the activation function for neuron j in layer l. It is computed as the dot product of the weights associated with the neuron and the activations from the previous layer, added to the bias. This weighted input plays a crucial role in the computation of the activation of the neuron and hence, the output of the neural network. The activation is computed by applying the activation function (such as the sigmoid function) to this weighted input. This notation helps in understanding the flow of computations in a neural network.\n",
      "\n",
      "Query[11]: 11. Why is the \\(w^{l}_{jk}\\) notation used instead of using j to index the input neuron and k to index the output neuron?\n",
      "Answer: The \\(w^{l}_{jk}\\) notation is used instead of using j to index the input neuron and k to index the output neuron to maintain the simplicity of the matrix-based approach. If j was used to index the input neuron and k to index the output neuron, the weight matrix in Equation 2.3 would need to be replaced by the transpose of the weight matrix. This would make the expression more complex and less intuitive, as it would not be as simple as \"applying the weight matrix to the activations\". So, to avoid this complication and maintain the easy simplicity, the \\(w^{l}_{jk}\\) notation is used.\n",
      "\n",
      "Query[12]: 12. Why is it beneficial to use matrix multiplication, vector addition, and vectorization in the context of neural networks?\n",
      "Answer: Matrix multiplication, vector addition, and vectorization are beneficial in the context of neural networks for several reasons:\n",
      "\n",
      "1. Efficiency: Matrix operations are computationally efficient and can be performed much faster than iterative loops, especially on modern hardware that is optimized for such operations. This is crucial when dealing with large-scale neural networks that have a large number of parameters.\n",
      "\n",
      "2. Conciseness: These operations provide a more succinct and concise way of expressing complex operations in neural networks. They simplify the notation, making the equations easier to understand and implement.\n",
      "\n",
      "3. Parallelization: Matrix operations can be easily parallelized, which can lead to significant speedups in the training and inference process of neural networks. This is particularly beneficial when using GPUs, which are designed to perform parallel computations.\n",
      "\n",
      "4. Library Support: Most programming languages have robust libraries (like NumPy in Python) that support matrix operations. These libraries have been optimized over many years, and using them can lead to more reliable and efficient code.\n",
      "\n",
      "5. Mathematical Convenience: Using matrix notation allows us to leverage linear algebra, which provides a powerful and flexible mathematical framework for manipulating and understanding the data and transformations within the network.\n",
      "\n",
      "Query[13]: 13. How does the expression \\(a^{l} = \\sigma(w^{l} a^{l-1} + b^{l})\\) help in understanding the behavior of a neural network?\n",
      "Answer: The expression \\(a^{l} = \\sigma(w^{l} a^{l-1} + b^{l})\\) provides a clear mathematical formulation of how a neural network operates. It illustrates that the activation of a neuron in layer \\(l\\) (represented by \\(a^{l}\\)) depends on the weighted sum of the activations in the previous layer (\\(a^{l-1}\\)), plus a bias term (\\(b^{l}\\)), passed through an activation function (\\(\\sigma\\)).\n",
      "\n",
      "This equation helps us understand the behavior of a neural network in a few ways:\n",
      "\n",
      "1. It encapsulates the fundamental operation of a neural network: taking inputs, applying weights, adding bias, and applying an activation function.\n",
      "2. It presents this operation in a matrix-based form, which allows us to apply these operations simultaneously to all neurons in a layer. This highlights the parallel nature of neural networks.\n",
      "3. It provides the basis for vectorization, which is a powerful technique used to speed up computations in neural networks. This is because matrix multiplication, vector addition, and applying an activation function can be done quickly and simultaneously on all elements of a vector with most matrix libraries.\n",
      "4. The equation explains how the data flows and is transformed from one layer to the next, hence revealing the network's architecture.\n",
      "5. It also explains why the weights and biases are essential parameters in the network, as they directly influence the output of each neuron. \n",
      "\n",
      "In summary, this equation provides a compact, global view of the operation of a neural network, helping us understand its behavior both conceptually and practically.\n",
      "\n",
      "Query[14]: 14. What is the importance of \\( z^{l-1} \\equiv w^{l} a^{l-1} + b^{l}\\) in the computation of \\(a^{l}\\)?\n",
      "Answer: The quantity \\( z^{l-1} \\equiv w^{l} a^{l-1} + b^{l}\\) is referred to as the weighted input to the neurons in layer l. This intermediate quantity plays a crucial role in the computation of \\(a^{l}\\). It represents the combined effect of the weights and activations from the previous layer, along with the bias, before the activation function is applied. It is significant because it encapsulates the input for the activation function for each neuron in layer l. This weighted input is then transformed by the activation function \\(\\sigma\\), which introduces non-linearity into the model, enabling the neural network to learn and model complex patterns. Furthermore, this weighted input \\( z^{l} \\) is also used later in the backpropagation algorithm for calculating the gradients.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "class StudentAssistant:\n",
    "    def __init__(self, model=\"gpt-4-0613\", result_length=500, with_prices=True):\n",
    "        self.model = model\n",
    "        self.with_prices = with_prices\n",
    "        self.result_length = result_length\n",
    "\n",
    "    def process(self, query: str, example_text: str):\n",
    "        # Construct conversational prompts\n",
    "        prompt = f\"{example_text}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "\n",
    "        # Generate responses using the Chat Completion interface\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=self.result_length,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        # Extract responses\n",
    "        answer = response.choices[0].message['content'] if response.choices else \"No answer available.\"\n",
    "        return answer\n",
    "\n",
    "# the original text\n",
    "example_text = new_text\n",
    "\n",
    "# Split the generated question string into a separate list of questions\n",
    "generated_questions_list = generated_questions.split('\\n')\n",
    "\n",
    "# Remove empty strings\n",
    "generated_questions_list = [q for q in generated_questions_list if q]\n",
    "\n",
    "# test query\n",
    "queries = generated_questions_list\n",
    "student_assistant = StudentAssistant()\n",
    "all_ans = ''\n",
    "for i, query in enumerate(queries):\n",
    "    print(f\"\\nQuery[{i + 1}]: {query}\")\n",
    "    answer = student_assistant.process(query, example_text)\n",
    "    all_ans += answer\n",
    "    print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcf2268",
   "metadata": {},
   "source": [
    "## similarity of answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f30295c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9036])\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# prepare the text\n",
    "text3 = all_ans\n",
    "text4 = new_text\n",
    "\n",
    "texts = [text3, text4]\n",
    "\n",
    "# encode the text\n",
    "encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Extract features from the embedding layer\n",
    "embeddings = model_output.last_hidden_state.mean(dim=1)\n",
    "\n",
    "# compute the similarity\n",
    "cosine_similarity_ans_GPT4 = torch.nn.functional.cosine_similarity(embeddings[0].unsqueeze(0), embeddings[1].unsqueeze(0))\n",
    "print(cosine_similarity_ans_GPT4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1e2200",
   "metadata": {},
   "source": [
    "## Generate questions and answers using GPT-3.5, and compute semantic relevance under the GPT-3.5 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9509da30",
   "metadata": {},
   "source": [
    "## Generate questions & calculate semantic relevance between text and questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e108563",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Questions:\n",
      "So instead, we use k to index the input neuron, and j to index the output neuron.\n",
      "\n",
      "Exam Questions:\n",
      "\n",
      "1. What does the expression \\(\\sigma (v)\\) denote?\n",
      "2. What is the difference between the neuron-by-neuron view and the global view of computing the output from a neural network?\n",
      "3. What is the purpose of the bias vector \\(b^{l}\\)?\n",
      "4. What is the purpose of the weight matrix \\(w^{l}\\)?\n",
      "5. How does the vectorized form of f work?\n",
      "6. What is the notation used for the weighted input to the neurons in layer l?\n",
      "7. What is the effect of vectorizing a function such as \\(\\sigma\\)?\n",
      "8. How is Equation 2.1 rewritten in a matrix form?\n",
      "9. What do the components of the bias vector represent?\n",
      "10. What does the expression \\(a^{l-1}_{k}\\) denote?\n",
      "11. What does the expression \\(w^{l}_{jk}\\) denote?\n",
      "12. What does the expression \\(a^{l}_{j}\\) denote?\n",
      "13. What is the difference between the components of \\(a^{l}\\) and \\(b^{l}\\)?\n",
      "14. What is the purpose of the activation vector \\(a^{l}\\)?\n"
     ]
    }
   ],
   "source": [
    "class TeacherAssistantGPT3:\n",
    "    def __init__(self, model=\"text-davinci-003\", result_length=500):\n",
    "        self.model = model\n",
    "        self.result_length = result_length\n",
    "\n",
    "    def generate_questions(self, text, num_questions=14):\n",
    "        prompt = f\"Based on the following text, generate {num_questions} relevant exam questions:\\n\\n{text}\"\n",
    "        \n",
    "        response = openai.Completion.create(\n",
    "            model=self.model,\n",
    "            prompt=prompt,\n",
    "            max_tokens=self.result_length,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        questions = response.choices[0].text.strip() if response.choices else \"No questions available.\"\n",
    "        return questions\n",
    "\n",
    "# the original text\n",
    "example_text = new_text\n",
    "\n",
    "# test TeacherAssistant class\n",
    "teacher_assistant = TeacherAssistantGPT3()\n",
    "\n",
    "# generate the questions\n",
    "generated_questionsGPT3 = teacher_assistant.generate_questions(example_text)\n",
    "print(f\"Generated Questions:\\n{generated_questionsGPT3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "32fbcb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8699])\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# prepare the text\n",
    "question_by_GPT3 =generated_questionsGPT3\n",
    "\n",
    "text = new_text\n",
    "texts = [question_by_GPT3, text]\n",
    "\n",
    "# encode text\n",
    "encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Extract features from the embedding layer\n",
    "embeddings = model_output.last_hidden_state.mean(dim=1)\n",
    "\n",
    "# compute similarity\n",
    "cosine_similarity_ques_GPT3 = torch.nn.functional.cosine_similarity(embeddings[0].unsqueeze(0), embeddings[1].unsqueeze(0))\n",
    "print(cosine_similarity_ques_GPT3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dfcac7",
   "metadata": {},
   "source": [
    "## Generate answers & calculate semantic relevance between text and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02a034a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query[1]: So instead, we use k to index the input neuron, and j to index the output neuron.\n",
      "Answer: This allows us to use the weight matrix directly in Equation 2.3 without needing to take the transpose, and also makes it easier to think of the weight matrix as connecting input neurons to output neurons.\n",
      "\n",
      "Query[2]: Exam Questions:\n",
      "Answer: 1. What is the formula for computing the output from a neural network?\n",
      "Answer: The formula is \\(j = \\sigma \\left(\\sum_{k} w^{l}_{jk} a^{l-1}_{k} + b^{l}_{j}\\right)\\)\n",
      "\n",
      "2. What is the vectorized form of this equation?\n",
      "Answer: The vectorized form of the equation is \\(a^{l} = \\sigma(w^{l} a^{l-1} + b^{l})\\)\n",
      "\n",
      "Query[3]: 1. What does the expression \\(\\sigma (v)\\) denote?\n",
      "Answer: The expression \\(\\sigma (v)\\) denotes the element-wise application of a function to a vector, such that the components of \\(\\sigma(v)\\) are just \\(\\sigma(v)_{j} = \\sigma(v_{j})\\).\n",
      "\n",
      "Query[4]: 2. What is the difference between the neuron-by-neuron view and the global view of computing the output from a neural network?\n",
      "Answer: The neuron-by-neuron view involves computing the output from a neural network one neuron at a time, while the global view involves computing the output from a neural network by applying the weight matrix to the activations, adding the bias vector, and then applying the sigma function. The global view is often simpler and more succinct, and is also more efficient in terms of computation time.\n",
      "\n",
      "Query[5]: 3. What is the purpose of the bias vector \\(b^{l}\\)?\n",
      "Answer: The purpose of the bias vector \\(b^{l}\\) is to add a shift to the weighted input \\(z^{l}\\). This shift can be used to adjust the output of the neural network.\n",
      "\n",
      "Query[6]: 4. What is the purpose of the weight matrix \\(w^{l}\\)?\n",
      "Answer: The purpose of the weight matrix \\(w^{l}\\) is to connect the neurons in the (l-1)-th layer to the neurons in the l-th layer. It contains the weights of the connections between these two layers of neurons.\n",
      "\n",
      "Query[7]: 5. How does the vectorized form of f work?\n",
      "Answer: The vectorized form of f works by applying a function such as σ to every element in a vector v. We use the notation σ(v) to denote this kind of elementwise application of a function. That is, the components of σ(v) are just σ(v)j = σ(vj). As an example, if we have the function f(x) = x2 then the vectorized form of f has the effect of squaring every element of the vector.\n",
      "\n",
      "Query[8]: 6. What is the notation used for the weighted input to the neurons in layer l?\n",
      "Answer: The notation used for the weighted input to the neurons in layer l is \\(z^{l}\\).\n",
      "\n",
      "Query[9]: 7. What is the effect of vectorizing a function such as \\(\\sigma\\)?\n",
      "Answer: Vectorizing a function such as \\(\\sigma\\) has the effect of applying the function to every element in a vector v. The components of \\(\\sigma(v)\\) are just \\(\\sigma(v)_{j} = \\sigma(v_{j})\\).\n",
      "\n",
      "Query[10]: 8. How is Equation 2.1 rewritten in a matrix form?\n",
      "Answer: Equation 2.1 is rewritten in a matrix form as: \n",
      "\\[a^{l} = \\sigma(w^{l} a^{l-1} + b^{l})\\]\n",
      "\n",
      "Query[11]: 9. What do the components of the bias vector represent?\n",
      "Answer: The components of the bias vector represent the values \\(b^{l}_{j}\\), one component for each neuron in the l-th layer.\n",
      "\n",
      "Query[12]: 10. What does the expression \\(a^{l-1}_{k}\\) denote?\n",
      "Answer: \\(a^{l-1}_{k}\\) denotes the activation of the k-th neuron in the (l-1)-th layer.\n",
      "\n",
      "Query[13]: 11. What does the expression \\(w^{l}_{jk}\\) denote?\n",
      "Answer: The expression \\(w^{l}_{jk}\\) denotes the weight connecting the j-th neuron in the (l-1)-th layer to the k-th neuron in the l-th layer.\n",
      "\n",
      "Query[14]: 12. What does the expression \\(a^{l}_{j}\\) denote?\n",
      "Answer: \\(a^{l}_{j}\\) denotes the activation of neuron j in layer l.\n",
      "\n",
      "Query[15]: 13. What is the difference between the components of \\(a^{l}\\) and \\(b^{l}\\)?\n",
      "Answer: The components of \\(a^{l}\\) are the activations \\(a^{l}_{j}\\), whereas the components of \\(b^{l}\\) are the values \\(b^{l}_{j}\\).\n",
      "\n",
      "Query[16]: 14. What is the purpose of the activation vector \\(a^{l}\\)?\n",
      "Answer: The activation vector \\(a^{l}\\) is used to compute the output from a neural network. Its components are the activations \\(a^{l}_{j}\\) for each neuron in the l-th layer.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "class StudentAssistantGPT3:\n",
    "    def __init__(self, model=\"text-davinci-003\", result_length=500, with_prices=True):\n",
    "        self.model = model\n",
    "        self.result_length = result_length\n",
    "\n",
    "    def process(self, query: str, example_text: str):\n",
    "        # Construct conversational prompts\n",
    "        prompt = f\"{example_text}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "\n",
    "        # Generate responses using the Completion interface\n",
    "        response = openai.Completion.create(\n",
    "            model=self.model,\n",
    "            prompt=prompt,\n",
    "            max_tokens=self.result_length,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        # Extract responses\n",
    "        answer = response.choices[0].text.strip() if response.choices else \"No answer available.\"\n",
    "\n",
    "        return answer\n",
    "\n",
    "example_text = new_text\n",
    "\n",
    "# Split the generated question string into a separate list of questions\n",
    "generated_questions_list = generated_questionsGPT3.split('\\n')\n",
    "\n",
    "# Remove empty strings\n",
    "generated_questions_list = [q for q in generated_questions_list if q]\n",
    "\n",
    "# test query\n",
    "queries = generated_questions_list\n",
    "student_assistant = StudentAssistantGPT3()\n",
    "all_ansGPT3 = ''\n",
    "for i, query in enumerate(queries):\n",
    "    print(f\"\\nQuery[{i + 1}]: {query}\")\n",
    "    answer = student_assistant.process(query, example_text)\n",
    "    all_ansGPT3 += answer\n",
    "    print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "05722b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9752])\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# prepare the text\n",
    "ansGPT3 = all_ansGPT3\n",
    "text = new_text\n",
    "\n",
    "texts = [new_text, ansGPT3]\n",
    "\n",
    "# encode text\n",
    "encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Extract features from the embedding layer\n",
    "embeddings = model_output.last_hidden_state.mean(dim=1)\n",
    "\n",
    "# compute similarity\n",
    "cosine_similarity_ans_GPT3 = torch.nn.functional.cosine_similarity(embeddings[0].unsqueeze(0), embeddings[1].unsqueeze(0))\n",
    "print(cosine_similarity_ans_GPT3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1503dd3f",
   "metadata": {},
   "source": [
    "## The chart of comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b1239a60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' \n",
    "\n",
    "# data\n",
    "ans_tensor_GPT4 = cosine_similarity_ans_GPT4[0].item()\n",
    "ans_tensor_GPT3 = cosine_similarity_ans_GPT3[0].item()\n",
    "ques_tensor_GPT4 = cosine_similarity_ques_GPT4[0].item()\n",
    "ques_tensor_GPT3 = cosine_similarity_ques_GPT3[0].item()\n",
    "\n",
    "group_te = [ques_tensor_GPT3, ans_tensor_GPT3]\n",
    "group_stu = [ques_tensor_GPT4, ans_tensor_GPT4]\n",
    "\n",
    "labels = ['The Comparison of TeacherAssistant System', 'The Comparison of StudentAssistant System']\n",
    "\n",
    "# Set the position of the bar chart\n",
    "x = np.arange(len(labels)) * 0.6  # the position of label\n",
    "width = 0.2  # width of chart\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "rects_te = ax.bar(x + width/2, group_te, width, label='Content generated by GPT-3.5')\n",
    "rects_stu = ax.bar(x - width/2, group_stu, width, label='Content generated by GPT-4')\n",
    "for rect in rects_te + rects_stu:\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2., 1.01*height, f'{height:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# Add titles and labels\n",
    "ax.set_ylabel('Similarity')\n",
    "ax.set_title('Comparison of the similarity between different models')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend(fontsize=8, loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb35b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bec4a006",
   "metadata": {},
   "source": [
    "## We choose another page with many formulas to test our system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe5cb057",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = r'D:\\manyformula.pdf'\n",
    "text = extract_text_from_pdf_with_pdfminer(pdf_path)\n",
    "\n",
    "output_txt_path = r'D:\\manyformula.txt'\n",
    "save_text_to_file(text, output_txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "efc7c225",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Based on the content of example_text, please identify all the formulas and change them into latex format. Then show me the new content.\n",
      "New_Text: The content with formulas in latex format is as follows:\n",
      "\n",
      "We’ll now prove the four fundamental equations (BP1)–(BP4). All four are consequences of the chain rule from multivariable calculus. If you’re comfortable with the chain rule, then I strongly encourage you to attempt the derivation yourself before reading on.\n",
      "\n",
      "Let’s begin with Equation (BP1), which gives an expression for the output error, $\\delta^l_j$. To prove this equation, recall that by definition\n",
      "\n",
      "$\\delta^L_j = \\frac{\\partial C}{\\partial z^L_j}$ (2.14)\n",
      "\n",
      "Applying the chain rule, we can re-express the partial derivative above in terms of partial derivatives with respect to the output activations,\n",
      "\n",
      "$\\delta^L_j = \\sum_k \\frac{\\partial C}{\\partial a^L_k} \\frac{\\partial a^L_k}{\\partial z^L_j}$ (2.15)\n",
      "\n",
      "where the sum is over all neurons k in the output layer. Of course, the output activation $a^L_k$ of the k-th neuron depends only on the weighted input $z^L_j$ for the j-th neuron when k = j. And so $\\frac{\\partial a^L_k}{\\partial z^L_j}$ vanishes when k ≠ j. As a result we can simplify the previous equation to\n",
      "\n",
      "$\\delta^L_j = \\frac{\\partial C}{\\partial a^L_j} \\frac{\\partial a^L_j}{\\partial z^L_j}$\n",
      "\n",
      "Recalling that $a^L_j = \\sigma(z^L_j)$ the second term on the right can be written as $\\sigma'(z^L_j)$, and the equation becomes\n",
      "\n",
      "$\\delta^L_j = \\frac{\\partial C}{\\partial a^L_j} \\sigma'(z^L_j)$ (2.16)\n",
      "\n",
      "which is just (BP1), in component form. Next, we’ll prove (BP2), which gives an equation for the error $\\delta^l_j$ in terms of the error in the next layer, $\\delta^{l+1}_j$. To do this, we want to rewrite $\\delta^l_j = \\frac{\\partial C}{\\partial z^l_j}$ in terms of $\\delta^{l+1}_k = \\frac{\\partial C}{\\partial z^{l+1}_k}$\n",
      "\n",
      "$\\delta^l_j = \\frac{\\partial C}{\\partial z^l_j} = \\sum_k \\frac{\\partial C}{\\partial z^{l+1}_k} \\frac{\\partial z^{l+1}_k}{\\partial z^l_j} = \\sum_k \\delta^{l+1}_k \\frac{\\partial z^{l+1}_k}{\\partial z^l_j}$ (2.18)\n",
      "\n",
      "where in the last line we have interchanged the two terms on the right-hand side, and substituted the definition of $\\delta^{l+1}_k$.\n",
      "\n",
      "To evaluate the first term on the last line, note that $z^{l+1}_k = \\sum_j w^{l+1}_{kj} a^l_j + b^{l+1}_k$\n",
      "\n",
      "Differentiating, we obtain $\\frac{\\partial z^{l+1}_k}{\\partial z^l_j} = w^{l+1}_{kj} \\sigma'(z^l_j)$ (2.20)\n"
     ]
    }
   ],
   "source": [
    "# the path of txt file\n",
    "txt_file_path = 'D:\\manyformula.txt'\n",
    "example_text_formula = read_text_from_file(txt_file_path)\n",
    "\n",
    "# text the query\n",
    "query = \"Based on the content of example_text, please identify all the formulas and change them into latex format. Then show me the new content.\"\n",
    "txt_recognizer = TxtRecognizer()\n",
    "\n",
    "print(f\"\\nQuery: {query}\")\n",
    "new_text_formula = txt_recognizer.process(query, example_text_formula)\n",
    "print(f\"New_Text: {new_text_formula}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b64cffa",
   "metadata": {},
   "source": [
    "## Generated questions and answers by GPT-4 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fb681089",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Questions:\n",
      "1. What are the four fundamental equations (BP1)–(BP4) that we are trying to prove?\n",
      "2. How does the chain rule from multivariable calculus apply to these equations?\n",
      "3. What is the expression for the output error, $\\delta^l_j$, given by Equation (BP1)?\n",
      "4. How is the chain rule used to re-express the partial derivative $\\frac{\\partial C}{\\partial z^L_j}$?\n",
      "5. Explain the terms of the equation $\\delta^L_j = \\sum_k \\frac{\\partial C}{\\partial a^L_k} \\frac{\\partial a^L_k}{\\partial z^L_j}$.\n",
      "6. How does the output activation $a^L_k$ of the k-th neuron depend on the weighted input $z^L_j$ for the j-th neuron?\n",
      "7. Why does $\\frac{\\partial a^L_k}{\\partial z^L_j}$ vanish when k ≠ j?\n",
      "8. What does the equation $\\delta^L_j = \\frac{\\partial C}{\\partial a^L_j} \\sigma'(z^L_j)$ represent?\n",
      "9. What is the aim of proving (BP2)?\n",
      "10. How can we rewrite $\\delta^l_j = \\frac{\\partial C}{\\partial z^l_j}$ in terms of $\\delta^{l+1}_k = \\frac{\\partial C}{\\partial z^{l+1}_k}$?\n",
      "11. How can we get from $\\delta^l_j = \\frac{\\partial C}{\\partial z^l_j}$ to $\\delta^l_j = \\sum_k \\delta^{l+1}_k \\frac{\\partial z^{l+1}_k}{\\partial z^l_j}$?\n",
      "12. Why is it valid to interchange the two terms on the right-hand side of the equation and substitute the definition of $\\delta^{l+1}_k$?\n",
      "13. How is $z^{l+1}_k = \\sum_j w^{l+1}_{kj} a^l_j + b^{l+1}_k$ obtained?\n",
      "14. What is the result of differentiating $z^{l+1}_k = \\sum_j w^{l+1}_{kj} a^l_j + b^{l+1}_k$?\n"
     ]
    }
   ],
   "source": [
    "# the original text\n",
    "example_text_formula = new_text_formula\n",
    "\n",
    "# test TeacherAssistant class\n",
    "teacher_assistant_formula = TeacherAssistant()\n",
    "\n",
    "# generate the questions\n",
    "generated_questions_formula = teacher_assistant_formula.generate_questions(example_text_formula)\n",
    "print(f\"Generated Questions:\\n{generated_questions_formula}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "482e8f28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query[1]: 1. What are the four fundamental equations (BP1)–(BP4) that we are trying to prove?\n",
      "Answer: The text does not provide specific details on the four fundamental equations (BP1)–(BP4) that are being proven. The context suggests they are related to backpropagation in neural networks and involve the application of the chain rule from multivariable calculus. Two of the equations are referenced during the discussion: (BP1) seems to concern the expression for the output error, $\\delta^l_j$, and (BP2) appears to be about the equation for the error $\\delta^l_j$ in terms of the error in the next layer, $\\delta^{l+1}_j$. However, the actual forms of equations (BP3) and (BP4) are not provided in the given text.\n",
      "\n",
      "Query[2]: 2. How does the chain rule from multivariable calculus apply to these equations?\n",
      "Answer: The chain rule from multivariable calculus is applied throughout these equations in order to derive new formulas or to simplify existing ones. \n",
      "\n",
      "1. In equation (2.14), the chain rule is applied to express the partial derivative of the cost function C with respect to the weighted input $z^L_j$.\n",
      "\n",
      "2. In equation (2.15), the chain rule is used again to re-express the original partial derivative in terms of partial derivatives with respect to the output activations. This is done by breaking down the original derivative into two steps: first finding how C changes with $a^L_k$, and then finding how $a^L_k$ changes with $z^L_j$.\n",
      "\n",
      "3. In the derivation of $\\delta^L_j = \\frac{\\partial C}{\\partial a^L_j} \\sigma'(z^L_j)$, the chain rule is used to differentiate the activation function $\\sigma(z^L_j)$, which is a function of $z^L_j$.\n",
      "\n",
      "4. In equation (2.18), the chain rule is used to break down the derivative of the cost function with respect to $z^l_j$ into the sum of the products of the derivative of the cost function with respect to $z^{l+1}_k$ and the derivative of $z^{l+1}_k$ with respect to $z^l_j$.\n",
      "\n",
      "5. Finally, the chain rule is used again to differentiate $z^{l+1}_k$ with respect to $z^l_j$ to obtain equation (2.20). \n",
      "\n",
      "In summary, the chain rule is a fundamental tool in these derivations, allowing the manipulation and simplification of complex derivatives into more manageable terms.\n",
      "\n",
      "Query[3]: 3. What is the expression for the output error, $\\delta^l_j$, given by Equation (BP1)?\n",
      "Answer: The expression for the output error, $\\delta^l_j$, given by Equation (BP1) is $\\delta^L_j = \\frac{\\partial C}{\\partial a^L_j} \\sigma'(z^L_j)$ (2.16).\n",
      "\n",
      "Query[4]: 4. How is the chain rule used to re-express the partial derivative $\\frac{\\partial C}{\\partial z^L_j}$?\n",
      "Answer: The chain rule is used to re-express the partial derivative $\\frac{\\partial C}{\\partial z^L_j}$ in terms of partial derivatives with respect to the output activations. This is done by applying the chain rule to the derivative of the cost function with respect to $z^L_j$, resulting in the equation \n",
      "\n",
      "$\\delta^L_j = \\sum_k \\frac{\\partial C}{\\partial a^L_k} \\frac{\\partial a^L_k}{\\partial z^L_j}$ \n",
      "\n",
      "where the sum is over all neurons k in the output layer. Here, the chain rule allows us to break down the derivative of the cost function with respect to $z^L_j$ into the sum of the products of the derivatives of the cost function with respect to the activation of each neuron k and the derivative of the activation of each neuron k with respect to $z^L_j$.\n",
      "\n",
      "Query[5]: 5. Explain the terms of the equation $\\delta^L_j = \\sum_k \\frac{\\partial C}{\\partial a^L_k} \\frac{\\partial a^L_k}{\\partial z^L_j}$.\n",
      "Answer: In the equation $\\delta^L_j = \\sum_k \\frac{\\partial C}{\\partial a^L_k} \\frac{\\partial a^L_k}{\\partial z^L_j}$, the terms are as follows:\n",
      "\n",
      "- $\\delta^L_j$: This term represents the output error for the j-th neuron in the L-th layer. It is the partial derivative of the cost function with respect to the weighted input $z^L_j$ to the j-th neuron in the L-th layer.\n",
      "\n",
      "- $\\frac{\\partial C}{\\partial a^L_k}$: This term is the partial derivative of the cost function C with respect to the activation $a^L_k$ of the k-th neuron in the L-th (output) layer. It represents how much the cost function changes with a slight change in the activation of the k-th neuron in the L-th layer.\n",
      "\n",
      "- $\\frac{\\partial a^L_k}{\\partial z^L_j}$: This term is the partial derivative of the activation $a^L_k$ of the k-th neuron in the L-th layer with respect to the weighted input $z^L_j$ to the j-th neuron in the same layer. It shows how much the activation of the k-th neuron changes with a slight change in the weighted input to the j-th neuron.\n",
      "\n",
      "- $\\sum_k$: This is a summation over all neurons k in the output layer. Each term in the sum contributes to the overall output error $\\delta^L_j$ for the j-th neuron.\n",
      "\n",
      "In essence, the equation is applying the chain rule to express the output error $\\delta^L_j$ in terms of the partial derivatives of the cost function and the activations with respect to the weighted inputs.\n",
      "\n",
      "Query[6]: 6. How does the output activation $a^L_k$ of the k-th neuron depend on the weighted input $z^L_j$ for the j-th neuron?\n",
      "Answer: The output activation $a^L_k$ of the k-th neuron depends on the weighted input $z^L_j$ for the j-th neuron only when k equals j. In this case, the output activation is defined as $a^L_j = \\sigma(z^L_j)$, where $\\sigma$ is the activation function. If k is not equal to j, then the partial derivative $\\frac{\\partial a^L_k}{\\partial z^L_j}$ vanishes, indicating no dependence.\n",
      "\n",
      "Query[7]: 7. Why does $\\frac{\\partial a^L_k}{\\partial z^L_j}$ vanish when k ≠ j?\n",
      "Answer: The term $\\frac{\\partial a^L_k}{\\partial z^L_j}$ vanishes when k ≠ j because the output activation $a^L_k$ of the k-th neuron only depends on the weighted input $z^L_j$ for the j-th neuron when k = j. In other words, the activation of a neuron is independent of the inputs to other neurons. Therefore, when k ≠ j, changing $z^L_j$ will not affect $a^L_k$, making the derivative zero.\n",
      "\n",
      "Query[8]: 8. What does the equation $\\delta^L_j = \\frac{\\partial C}{\\partial a^L_j} \\sigma'(z^L_j)$ represent?\n",
      "Answer: The equation $\\delta^L_j = \\frac{\\partial C}{\\partial a^L_j} \\sigma'(z^L_j)$ represents the output error of the jth neuron in the Lth layer of a neural network. The output error is calculated as the product of the derivative of the cost function with respect to the activation of the jth neuron and the derivative of the sigmoid function applied to the weighted input of the jth neuron. This is also referred to as the backpropagation equation (BP1), which is used to compute the error terms during the training of neural networks.\n",
      "\n",
      "Query[9]: 9. What is the aim of proving (BP2)?\n",
      "Answer: The aim of proving (BP2) is to establish an equation for the error in a given layer in terms of the error in the next layer. This is crucial for the process of backpropagation in neural networks, where errors are propagated backwards from the output layer to the input layer, allowing the model to adjust the weights and biases to minimize the error for future predictions.\n",
      "\n",
      "Query[10]: 10. How can we rewrite $\\delta^l_j = \\frac{\\partial C}{\\partial z^l_j}$ in terms of $\\delta^{l+1}_k = \\frac{\\partial C}{\\partial z^{l+1}_k}$?\n",
      "Answer: We can rewrite $\\delta^l_j = \\frac{\\partial C}{\\partial z^l_j}$ in terms of $\\delta^{l+1}_k = \\frac{\\partial C}{\\partial z^{l+1}_k}$ by using the chain rule as follows:\n",
      "\n",
      "$\\delta^l_j = \\frac{\\partial C}{\\partial z^l_j} = \\sum_k \\frac{\\partial C}{\\partial z^{l+1}_k} \\frac{\\partial z^{l+1}_k}{\\partial z^l_j} = \\sum_k \\delta^{l+1}_k \\frac{\\partial z^{l+1}_k}{\\partial z^l_j}$ \n",
      "\n",
      "This equation sums over all neurons k in the next layer (l+1). The term $\\frac{\\partial z^{l+1}_k}{\\partial z^l_j}$ can be further evaluated as $w^{l+1}_{kj} \\sigma'(z^l_j)$ which is the weight of the connection from the j-th neuron in the l-th layer to the k-th neuron in the (l+1)-th layer times the derivative of the activation function evaluated at the weighted input to the j-th neuron in the l-th layer. This gives us a new perspective on the error $\\delta^l_j$ in terms of the error in the next layer $\\delta^{l+1}_k$.\n",
      "\n",
      "Query[11]: 11. How can we get from $\\delta^l_j = \\frac{\\partial C}{\\partial z^l_j}$ to $\\delta^l_j = \\sum_k \\delta^{l+1}_k \\frac{\\partial z^{l+1}_k}{\\partial z^l_j}$?\n",
      "Answer: We get from $\\delta^l_j = \\frac{\\partial C}{\\partial z^l_j}$ to $\\delta^l_j = \\sum_k \\delta^{l+1}_k \\frac{\\partial z^{l+1}_k}{\\partial z^l_j}$ by applying the chain rule of calculus.\n",
      "\n",
      "The chain rule allows us to express the derivative of a function with respect to one variable in terms of the derivative of that function with respect to another variable. In this case, we express the derivative of the cost function C with respect to the weighted input $z^l_j$ of the j-th neuron in layer l, as a sum over all neurons k in the next layer (l+1), of the product of the derivative of the cost function with respect to the weighted input $z^{l+1}_k$ of the k-th neuron in layer (l+1), and the derivative of the weighted input $z^{l+1}_k$ with respect to the weighted input $z^l_j$ of the j-th neuron in layer l.\n",
      "\n",
      "This is done by the following steps:\n",
      "\n",
      "1. We start with $\\delta^l_j = \\frac{\\partial C}{\\partial z^l_j}$.\n",
      "\n",
      "2. Then, we apply the chain rule to express this derivative as a sum over all neurons k in the next layer (l+1) of the product of the derivative of C with respect to $z^{l+1}_k$ and the derivative of $z^{l+1}_k$ with respect to $z^l_j$: $\\delta^l_j = \\sum_k \\frac{\\partial C}{\\partial z^{l+1}_k} \\frac{\\partial z^{l+1}_k}{\\partial z^l_j}$.\n",
      "\n",
      "3. Finally, we substitute the definition of $\\delta^{l+1}_k$ into the sum to get $\\delta^l_j = \\sum_k \\delta^{l+1}_k \\frac{\\partial z^{l+1}_k}{\\partial z^l_j}$.\n",
      "\n",
      "Query[12]: 12. Why is it valid to interchange the two terms on the right-hand side of the equation and substitute the definition of $\\delta^{l+1}_k$?\n",
      "Answer: It is valid to interchange the two terms on the right-hand side of the equation and substitute the definition of $\\delta^{l+1}_k$ because of the property of multiplication in calculus. In calculus, the order of multiplication does not change the result (commutative property of multiplication). Therefore, we can interchange the terms without changing the value of the expression. As for the substitution of the definition of $\\delta^{l+1}_k$, it is valid because it's a direct application of the definition of $\\delta^{l+1}_k$. This is a basic principle in calculus where you can substitute equivalent expressions to simplify calculations or proofs.\n",
      "\n",
      "Query[13]: 13. How is $z^{l+1}_k = \\sum_j w^{l+1}_{kj} a^l_j + b^{l+1}_k$ obtained?\n",
      "Answer: The equation $z^{l+1}_k = \\sum_j w^{l+1}_{kj} a^l_j + b^{l+1}_k$ is derived from the basic structure of a neural network. In a neural network, each neuron in one layer is connected to every neuron in the next layer. The value of a neuron in the next layer ($z^{l+1}_k$) is calculated by summing the products of the weights ($w^{l+1}_{kj}$) and the activations ($a^l_j$) of all neurons in the current layer, and then adding a bias ($b^{l+1}_k$). \n",
      "\n",
      "In other words, the activation of the k-th neuron in the (l+1)-th layer is calculated by summing over all j neurons in the l-th layer, the product of the weight connecting the j-th neuron in the l-th layer to the k-th neuron in the (l+1)-th layer and the activation of the j-th neuron in the l-th layer, and then adding the bias of the k-th neuron in the (l+1)-th layer. This reflects the fact that each neuron's output is a weighted sum of its inputs plus a bias term.\n",
      "\n",
      "Query[14]: 14. What is the result of differentiating $z^{l+1}_k = \\sum_j w^{l+1}_{kj} a^l_j + b^{l+1}_k$?\n",
      "Answer: The result of differentiating $z^{l+1}_k = \\sum_j w^{l+1}_{kj} a^l_j + b^{l+1}_k$ is $\\frac{\\partial z^{l+1}_k}{\\partial z^l_j} = w^{l+1}_{kj} \\sigma'(z^l_j)$ (2.20).\n"
     ]
    }
   ],
   "source": [
    "# the original text\n",
    "example_text_formula = new_text_formula\n",
    "\n",
    "# Split the generated question string into a separate list of questions\n",
    "generated_questions_list_formula = generated_questions_formula.split('\\n')\n",
    "\n",
    "# Remove empty strings\n",
    "generated_questions_list_formula = [q for q in generated_questions_list_formula if q]\n",
    "\n",
    "# test query\n",
    "queries_formula = generated_questions_list_formula\n",
    "student_assistant_formula = StudentAssistant()\n",
    "all_ans_formula = ''\n",
    "for i, query in enumerate(queries_formula):\n",
    "    print(f\"\\nQuery[{i + 1}]: {query}\")\n",
    "    answer_formula = student_assistant_formula.process(query, example_text_formula)\n",
    "    all_ans_formula += answer_formula\n",
    "    print(f\"Answer: {answer_formula}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ac018",
   "metadata": {},
   "source": [
    "## Calculate the similarity of questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4ef86b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9707])\n"
     ]
    }
   ],
   "source": [
    "# Check the relativity between the text generated by GPT-4-0613 and original textbook content\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# prepare text\n",
    "question_by_GPT4_formula =generated_questions_formula\n",
    "\n",
    "question_from_text_formula = new_text_formula\n",
    "texts_formula = [question_from_text_formula, question_by_GPT4_formula]\n",
    "\n",
    "# encode text\n",
    "encoded_input = tokenizer(texts_formula, padding=True, truncation=True, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Extract features from the embedding layer\n",
    "embeddings = model_output.last_hidden_state.mean(dim=1)\n",
    "\n",
    "# compute the similarity\n",
    "cosine_similarity_ques_GPT4_formula = torch.nn.functional.cosine_similarity(embeddings[0].unsqueeze(0), embeddings[1].unsqueeze(0))\n",
    "print(cosine_similarity_ques_GPT4_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c3525acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9627])\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# prepare the text\n",
    "texts_formula = [all_ans_formula, new_text_formula]\n",
    "\n",
    "# encode the text\n",
    "encoded_input = tokenizer(texts_formula, padding=True, truncation=True, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Extract features from the embedding layer\n",
    "embeddings = model_output.last_hidden_state.mean(dim=1)\n",
    "\n",
    "# compute the similarity\n",
    "cosine_similarity_ans_GPT4_formula = torch.nn.functional.cosine_similarity(embeddings[0].unsqueeze(0), embeddings[1].unsqueeze(0))\n",
    "print(cosine_similarity_ans_GPT4_formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e107e21",
   "metadata": {},
   "source": [
    "## Generated questions and answers by GPT-3.5 model and calculate similarity respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc63b314",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Questions:\n",
      "Exam Questions:\n",
      "\n",
      "1. What does the expression \\(\\sigma(v)\\) denote?\n",
      "2. What is the effect of applying the vectorized form of the function \\(f (x) = x^{2}\\) to the vector \\(\\begin{matrix} 2 \\\\ 3 \\end{matrix}\\)?\n",
      "3. What is the purpose of defining a weight matrix \\(w^{l}\\) for each layer, l?\n",
      "4. What is the purpose of defining a bias vector \\(b^{l}\\) for each layer, l?\n",
      "5. What is the purpose of defining an activation vector \\(a^{l}\\) for each layer, l?\n",
      "6. How does Equation 2.1 differ from the matrix form?\n",
      "7. What is the quirk in the \\(w^{l}_{jk}\\) notation?\n",
      "8. What is the purpose of computing the intermediate quantity \\( z^{l-1} \\equiv w^{l} a^{l-1} + b^{l}\\)?\n",
      "9. What is the difference between the neuron-by-neuron view and the global view of computing the activations in a layer?\n",
      "10. How is the expression \\(a^{l} = \\sigma(w^{l} a^{l-1} + b^{l})\\) useful in practice?\n",
      "11. What is the purpose of Equation 2.3?\n",
      "12. What is the effect of the vectorized form of the function \\(f (x) = x^2\\) on a vector?\n",
      "13. What is the value of \\(b^{l}_{j}\\) for each neuron in the l-th layer?\n",
      "14. How does the expression \\(a^{l} = \\sigma(w^{l} a^{l-1} + b^{l})\\) help to escape index hell?\n"
     ]
    }
   ],
   "source": [
    "# the original text\n",
    "example_text_formula = new_text_formula\n",
    "\n",
    "# test TeacherAssistant class\n",
    "teacher_assistant_formula = TeacherAssistantGPT3()\n",
    "\n",
    "# generate the questions\n",
    "generated_questionsGPT3_formula = teacher_assistant_formula.generate_questions(example_text)\n",
    "print(f\"Generated Questions:\\n{generated_questionsGPT3_formula}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "922c4055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9627])\n"
     ]
    }
   ],
   "source": [
    "# Check the relativity between the text generated by GPT-3.5 and original textbook content\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# prepare the text\n",
    "question_by_GPT3_formula =generated_questionsGPT3_formula\n",
    "\n",
    "text_formula = new_text_formula\n",
    "texts = [question_by_GPT3_formula, text_formula]\n",
    "\n",
    "# encode text\n",
    "encoded_input = tokenizer(texts_formula, padding=True, truncation=True, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Extract features from the embedding layer\n",
    "embeddings = model_output.last_hidden_state.mean(dim=1)\n",
    "\n",
    "# compute similarity\n",
    "cosine_similarity_ques_GPT3_formula = torch.nn.functional.cosine_similarity(embeddings[0].unsqueeze(0), embeddings[1].unsqueeze(0))\n",
    "print(cosine_similarity_ques_GPT3_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a89260b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query[1]: Exam Questions:\n",
      "Answer: Substituting this into the previous equation, we get\n",
      "\n",
      "$\\delta^l_j = \\sum_k \\delta^{l+1}_k w^{l+1}_{kj} \\sigma'(z^l_j)$ (2.21)\n",
      "\n",
      "which is just (BP2).\n",
      "\n",
      "Query[2]: 1. What does the expression \\(\\sigma(v)\\) denote?\n",
      "Answer: The expression \\(\\sigma(v)\\) denotes an activation function, which is used to map a weighted sum of inputs (v) to an output.\n",
      "\n",
      "Query[3]: 2. What is the effect of applying the vectorized form of the function \\(f (x) = x^{2}\\) to the vector \\(\\begin{matrix} 2 \\\\ 3 \\end{matrix}\\)?\n",
      "Answer: The effect of applying the vectorized form of the function f(x) = x2 to the vector (2, 3) is to calculate the squares of both numbers, resulting in (4, 9).\n",
      "\n",
      "Query[4]: 3. What is the purpose of defining a weight matrix \\(w^{l}\\) for each layer, l?\n",
      "Answer: The purpose of defining a weight matrix \\(w^{l}\\) for each layer, l is to enable the neural network to learn the best parameters for the model, thus optimizing the output of the model for a given input. The weights in the matrix represent the strength of the connection between neurons in different layers, and the weights are adjusted during training to find the best combination of parameters that will produce the desired output.\n",
      "\n",
      "Query[5]: 4. What is the purpose of defining a bias vector \\(b^{l}\\) for each layer, l?\n",
      "Answer: The purpose of defining a bias vector \\(b^l\\) for each layer, l, is to capture the effect of differences in the input data. By adding the bias vector to the input vector, the neural network is able to account for variations in the input and output data due to factors such as noise or outliers. The bias vector provides the network with a way to adjust its predictions based on the input data in order to make more accurate predictions.\n",
      "\n",
      "Query[6]: 5. What is the purpose of defining an activation vector \\(a^{l}\\) for each layer, l?\n",
      "Answer: The purpose of defining an activation vector $a^l$ for each layer, l, is to represent the output of a given layer in the neural network. This activation vector is used to calculate the output error $\\delta^l_j$ using the chain rule from multivariable calculus.\n",
      "\n",
      "Query[7]: 6. How does Equation 2.1 differ from the matrix form?\n",
      "Answer: Equation 2.1 is the component form of the equation, while the matrix form is a more condensed form of the equation that is written as a matrix equation.\n",
      "\n",
      "Query[8]: 7. What is the quirk in the \\(w^{l}_{jk}\\) notation?\n",
      "Answer: The quirk in the \\(w^{l}_{jk}\\) notation is that the \"j\" and \"k\" indices refer to the neuron in the current layer (j) and the neuron in the next layer (k).\n",
      "\n",
      "Query[9]: 8. What is the purpose of computing the intermediate quantity \\( z^{l-1} \\equiv w^{l} a^{l-1} + b^{l}\\)?\n",
      "Answer: The purpose of computing the intermediate quantity \\( z^{l-1} \\equiv w^{l} a^{l-1} + b^{l}\\) is to determine the weighted inputs to the activation functions for the neurons in the next layer. This allows us to calculate the output activations for the neurons in the next layer, which are needed to calculate the errors in the neurons of the current layer using the chain rule.\n",
      "\n",
      "Query[10]: 9. What is the difference between the neuron-by-neuron view and the global view of computing the activations in a layer?\n",
      "Answer: The neuron-by-neuron view involves computing the activations of each neuron separately, while the global view involves computing the activations of a layer as a whole.\n",
      "\n",
      "Query[11]: 10. How is the expression \\(a^{l} = \\sigma(w^{l} a^{l-1} + b^{l})\\) useful in practice?\n",
      "Answer: This expression is useful in practice because it allows us to calculate the activations of each layer in a neural network based on the weights and biases of the network. By computing the activations of each layer, we can then use them to calculate the output of the network.\n",
      "\n",
      "Query[12]: 11. What is the purpose of Equation 2.3?\n",
      "Answer: Equation 2.3 is used to prove the four fundamental equations (BP1)-(BP4).\n",
      "\n",
      "Query[13]: 12. What is the effect of the vectorized form of the function \\(f (x) = x^2\\) on a vector?\n",
      "Answer: The vectorized form of the function \\(f (x) = x^2\\) will have the effect of squaring each element of the vector.\n",
      "\n",
      "Query[14]: 13. What is the value of \\(b^{l}_{j}\\) for each neuron in the l-th layer?\n",
      "Answer: \\(b^{l}_{j}\\) is the bias of the j-th neuron in the l-th layer.\n",
      "\n",
      "Query[15]: 14. How does the expression \\(a^{l} = \\sigma(w^{l} a^{l-1} + b^{l})\\) help to escape index hell?\n",
      "Answer: The expression \\(a^{l} = \\sigma(w^{l} a^{l-1} + b^{l})\\) helps to escape index hell by making it easier to express equations in terms of the activations in the previous layer. This is done by taking the derivative of the expression with respect to the activations in the previous layer, which allows us to rewrite equations with fewer indices and thus avoid index hell.\n"
     ]
    }
   ],
   "source": [
    "example_text_formula = new_text_formula\n",
    "\n",
    "# Split the generated question string into a separate list of questions\n",
    "generated_questions_list_formula = generated_questionsGPT3_formula.split('\\n')\n",
    "\n",
    "# Remove empty strings\n",
    "generated_questions_list_formula = [q for q in generated_questions_list_formula if q]\n",
    "\n",
    "# test query\n",
    "queries_formula = generated_questions_list_formula\n",
    "student_assistant_formula = StudentAssistantGPT3()\n",
    "all_ansGPT3_formula = ''\n",
    "for i, query in enumerate(queries_formula):\n",
    "    print(f\"\\nQuery[{i + 1}]: {query}\")\n",
    "    answer_formula = student_assistant_formula.process(query, example_text_formula)\n",
    "    all_ansGPT3_formula += answer_formula\n",
    "    print(f\"Answer: {answer_formula}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6c54099d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9326])\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# prepare the text\n",
    "ansGPT3_formula = all_ansGPT3_formula\n",
    "text_formula = new_text_formula\n",
    "\n",
    "texts_formula = [new_text_formula, ansGPT3_formula]\n",
    "\n",
    "# encode text\n",
    "encoded_input = tokenizer(texts_formula, padding=True, truncation=True, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Extract features from the embedding layer\n",
    "embeddings = model_output.last_hidden_state.mean(dim=1)\n",
    "\n",
    "# compute similarity\n",
    "cosine_similarity_ans_GPT3_formula = torch.nn.functional.cosine_similarity(embeddings[0].unsqueeze(0), embeddings[1].unsqueeze(0))\n",
    "print(cosine_similarity_ans_GPT3_formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e13b38",
   "metadata": {},
   "source": [
    "## Plot the comparison figure for page with many formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c7c13171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data\n",
    "ans_tesor_GPT4_formula = cosine_similarity_ans_GPT4_formula[0].item()\n",
    "ans_tensor_GPT3_formula = cosine_similarity_ans_GPT3_formula[0].item()\n",
    "ques_tensor_GPT4_formula = cosine_similarity_ques_GPT4_formula[0].item()\n",
    "ques_tensor_GPT3_formula = cosine_similarity_ques_GPT3_formula[0].item()\n",
    "\n",
    "group_ans_formula = [ques_tensor_GPT3_formula, ans_tensor_GPT3_formula]\n",
    "group_ques_formula = [ques_tensor_GPT4_formula, ans_tesor_GPT4_formula]\n",
    "\n",
    "labels = ['The Comparison of TeacherAssistant System', 'The Comparison of StudentAssistant System']\n",
    "\n",
    "# Set the position of the bar chart\n",
    "x = np.arange(len(labels)) * 0.6  # the position of label\n",
    "width = 0.2  # width of chart\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "rects1_formula = ax.bar(x - width/2, group_ques_formula, width, label='Content generated by GPT-4')\n",
    "rects2_formula = ax.bar(x + width/2, group_ans_formula, width, label='Content generated by GPT-3.5')\n",
    "for rect in rects1_formula + rects2_formula:\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2., 1.01*height,\n",
    "            f'{height:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# Add titles and labels\n",
    "ax.set_ylabel('Similarity')\n",
    "ax.set_title('Comparison of the similarity between different models')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend(fontsize=8, loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
